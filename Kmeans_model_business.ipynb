{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85d45ad8-8305-4025-8544-d368b55afb6f",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "847605b0-05c7-4e35-96d6-6226ae216e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97ec734-2bd3-4a1e-9acd-a55757382360",
   "metadata": {},
   "source": [
    "### Setup connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "935793d9-36f6-429a-b354-45b067e91aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery project ID: valiant-song-371916\n",
      "BigQuery dataset: yelp\n",
      "BiqQuery dataset directory: valiant-song-371916.yelp\n"
     ]
    }
   ],
   "source": [
    "REGION = 'us-central1'\n",
    "#Get Project ID\n",
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'yelp'\n",
    "bq_dir = BQ_PROJECT + '.'+BQ_DATASET\n",
    "print('BigQuery project ID:', BQ_PROJECT)\n",
    "print('BigQuery dataset:', BQ_DATASET)\n",
    "print('BiqQuery dataset directory:', bq_dir)\n",
    "#Set clients:\n",
    "gcs = storage.Client(project = PROJECT_ID)\n",
    "bq = bigquery.Client(project = PROJECT_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f485c5c-f3d8-4171-be2f-b116e4971b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables contained in 'yelp':\n",
      "valiant-song-371916.yelp.business\n",
      "valiant-song-371916.yelp.checkin\n",
      "valiant-song-371916.yelp.reviews\n",
      "valiant-song-371916.yelp.tip\n",
      "valiant-song-371916.yelp.user\n"
     ]
    }
   ],
   "source": [
    "### Get the list of tables from the dataset yelp:\n",
    "dataset_id = BQ_DATASET\n",
    "tables = bq.list_tables(dataset_id)  # Make an API request.\n",
    "\n",
    "print(\"Tables contained in '{}':\".format(dataset_id))\n",
    "for table in tables:\n",
    "    print(\"{}.{}.{}\".format(table.project, table.dataset_id, table.table_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f544755-4f5f-40fa-be07-2bceecee9e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'valiant-song-371916.yelp'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_dir = BQ_PROJECT + '.'+BQ_DATASET\n",
    "bq_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08673988-d89c-47b2-b3d7-0c756a5d5ca5",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23fbf53d-675d-4f6e-94e5-e546d7688f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>attributes</th>\n",
       "      <th>state</th>\n",
       "      <th>is_open</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>hours</th>\n",
       "      <th>stars</th>\n",
       "      <th>latitude</th>\n",
       "      <th>address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>business_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Real Estate Agents, Home Services, Real Estate</td>\n",
       "      <td>None</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>46032</td>\n",
       "      <td>Jennie Deckert</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.969300</td>\n",
       "      <td></td>\n",
       "      <td>-86.165002</td>\n",
       "      <td>Carmel</td>\n",
       "      <td>REwfwz-_-CMQ7Np5UVi9Qg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Banks &amp; Credit Unions, Financial Services</td>\n",
       "      <td>None</td>\n",
       "      <td>DE</td>\n",
       "      <td>1</td>\n",
       "      <td>19850</td>\n",
       "      <td>Chase JP Morgan Bank Credit Card Services</td>\n",
       "      <td>111</td>\n",
       "      <td>None</td>\n",
       "      <td>1.5</td>\n",
       "      <td>39.749361</td>\n",
       "      <td></td>\n",
       "      <td>-75.643331</td>\n",
       "      <td>Wilmington</td>\n",
       "      <td>7PDi_iyik3jraDAzWwwR4Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Couriers &amp; Delivery Services, Local Services, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>TN</td>\n",
       "      <td>1</td>\n",
       "      <td>37027</td>\n",
       "      <td>Nashville Delivers</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>3.5</td>\n",
       "      <td>36.002397</td>\n",
       "      <td>6591 Bluff Rd</td>\n",
       "      <td>-86.702381</td>\n",
       "      <td>Brentwood</td>\n",
       "      <td>qFX8IdomeBVhDPCSyz2aRg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Banks &amp; Credit Unions, Financial Services</td>\n",
       "      <td>None</td>\n",
       "      <td>PA</td>\n",
       "      <td>1</td>\n",
       "      <td>19083</td>\n",
       "      <td>TD Bank Havertown</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>1.5</td>\n",
       "      <td>39.985661</td>\n",
       "      <td>120 W Eagle Rd</td>\n",
       "      <td>-75.314844</td>\n",
       "      <td>Haverford</td>\n",
       "      <td>FC6ef4rMMZKNov_-A9M6iQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gas Stations, Automotive, Towing</td>\n",
       "      <td>None</td>\n",
       "      <td>NJ</td>\n",
       "      <td>1</td>\n",
       "      <td>08057</td>\n",
       "      <td>Lott's Service</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>1.5</td>\n",
       "      <td>39.973753</td>\n",
       "      <td>908 N Lenola Rd, Ste 3</td>\n",
       "      <td>-74.995949</td>\n",
       "      <td>Moorestown</td>\n",
       "      <td>DcUDIlxFsvqPvFh8_lb4Sw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          categories attributes state  \\\n",
       "0     Real Estate Agents, Home Services, Real Estate       None    IN   \n",
       "1          Banks & Credit Unions, Financial Services       None    DE   \n",
       "2  Couriers & Delivery Services, Local Services, ...       None    TN   \n",
       "3          Banks & Credit Unions, Financial Services       None    PA   \n",
       "4                   Gas Stations, Automotive, Towing       None    NJ   \n",
       "\n",
       "   is_open postal_code                                       name  \\\n",
       "0        1       46032                             Jennie Deckert   \n",
       "1        1       19850  Chase JP Morgan Bank Credit Card Services   \n",
       "2        1       37027                         Nashville Delivers   \n",
       "3        1       19083                          TD Bank Havertown   \n",
       "4        1       08057                             Lott's Service   \n",
       "\n",
       "   review_count hours  stars   latitude                 address  longitude  \\\n",
       "0             7  None    5.0  39.969300                         -86.165002   \n",
       "1           111  None    1.5  39.749361                         -75.643331   \n",
       "2             7  None    3.5  36.002397           6591 Bluff Rd -86.702381   \n",
       "3             6  None    1.5  39.985661          120 W Eagle Rd -75.314844   \n",
       "4             8  None    1.5  39.973753  908 N Lenola Rd, Ste 3 -74.995949   \n",
       "\n",
       "         city             business_id  \n",
       "0      Carmel  REwfwz-_-CMQ7Np5UVi9Qg  \n",
       "1  Wilmington  7PDi_iyik3jraDAzWwwR4Q  \n",
       "2   Brentwood  qFX8IdomeBVhDPCSyz2aRg  \n",
       "3   Haverford  FC6ef4rMMZKNov_-A9M6iQ  \n",
       "4  Moorestown  DcUDIlxFsvqPvFh8_lb4Sw  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Get the first 5 instances from business table:\n",
    "query = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM {bq_dir}.business\n",
    "            LIMIT 5\n",
    "    \"\"\"\n",
    "bq_cm = bq.query(query = query).to_dataframe()\n",
    "bq_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c57deeb6-074d-414b-ae2a-9a95da7a09d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (83143, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>total_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beauty &amp; Spas, Nail Salons</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Restaurants, Pizza</td>\n",
       "      <td>935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nail Salons, Beauty &amp; Spas</td>\n",
       "      <td>934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pizza, Restaurants</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Restaurants, Mexican</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   categories  total_reviews\n",
       "0  Beauty & Spas, Nail Salons           1012\n",
       "1          Restaurants, Pizza            935\n",
       "2  Nail Salons, Beauty & Spas            934\n",
       "3          Pizza, Restaurants            821\n",
       "4        Restaurants, Mexican            727"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Get the 5 most popular categories in yelp reviews\n",
    "query = f\"\"\"\n",
    "            SELECT categories, count(*) as total_reviews\n",
    "            FROM {bq_dir}.business\n",
    "            GROUP BY categories\n",
    "            ORDER BY total_reviews DESC\n",
    "    \"\"\"\n",
    "cat_df = bq.query(query = query).to_dataframe()\n",
    "print('Df shape:', cat_df.shape)\n",
    "cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f64b7c4d-255d-41c2-af25-0ce138e55019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83138    Fitness & Instruction, Active Life, Arts & Ent...\n",
       "83139    Tapas Bars, Bars, Restaurants, Nightlife, Japa...\n",
       "83140    Barre Classes, Active Life, Cycling Classes, F...\n",
       "83141    Kids Activities, Skating Rinks, Recreation Cen...\n",
       "83142    Thrift Stores, Antiques, Furniture Stores, Hom...\n",
       "Name: categories, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df['categories'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e14d98-3951-4fd3-8177-f22565023e37",
   "metadata": {},
   "source": [
    "The categories from yelp dataset was not fully defined with more than 80000 categories or combined multiple categories, which could be due to the keywords for each business. \n",
    "\n",
    "Thus, we will need to build a model to classify these labels into different categories. Particularly, we will build a K-means clustering model for this specific tasks (See the section below)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc99962-c5c2-4a32-97b2-82a4ee055dfc",
   "metadata": {},
   "source": [
    "### K-means clustering model to determine the business categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5a119b9-21ba-4604-91a2-6acb5ea74250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "#from sklearn.metrics.scorer import SCORERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cedd33-60d0-4355-b3dd-d36d52a38c57",
   "metadata": {},
   "source": [
    "#### Prepare data for K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a53f782-64b6-4e21-8ec4-b7c91dff210c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beauty and Spas  Nail Salons', 'Restaurants  Pizza', 'Nail Salons  Beauty and Spas', 'Pizza  Restaurants', 'Restaurants  Mexican']\n"
     ]
    }
   ],
   "source": [
    "# Define the categories after clean up:\n",
    "def split_and_replace(word):\n",
    "    return str(word).replace('&','and').split(',')\n",
    "\n",
    "categories = cat_df['categories'].apply(lambda x: split_and_replace(x))\n",
    "\n",
    "# Convert the categories to a list of strings\n",
    "categories = [\" \".join(category) for category in categories]\n",
    "print(categories[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22c750a-5a76-4581-bab0-98df11790945",
   "metadata": {},
   "source": [
    "#### Text Normalization\n",
    "Here we will convert text to numerical features using CountVectorizer() and implement two methods for text normalization, which includes the StandardScaler() to remove the mean and scaling to unit variance, and the TF-IDF transformer for text normalization. Performance of KMeans with different normalizer is evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fd0899f-821c-4ec6-a0c8-1c222f562e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CountVectorizer to transform the categories into numerical features\n",
    "vectorizer = CountVectorizer()\n",
    "X_vect = vectorizer.fit_transform(categories)\n",
    "\n",
    "#Normalization\n",
    "scaler = StandardScaler(with_mean = False)\n",
    "X_normed = scaler.fit_transform(X_vect)\n",
    "\n",
    "#Transform to TF-IDF\n",
    "transformer = TfidfTransformer()\n",
    "X_tfdf = transformer.fit_transform(X_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "395b4eac-8e67-45d0-89ab-70298a090356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08512171340727473\n"
     ]
    }
   ],
   "source": [
    "### Check the kmean model with non-normalized dataset\n",
    "model = KMeans(n_clusters=20)\n",
    "model.fit(X_vect.toarray())\n",
    "\n",
    "cluster_assigment = model.predict(X_vect.toarray())\n",
    "\n",
    "# Evaluate the model using various metrics\n",
    "silhouette = silhouette_score(X_vect, cluster_assigment)\n",
    "print(silhouette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27c57d70-8e6e-43a9-a5ee-1f7c41e1d173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11983316966146747\n"
     ]
    }
   ],
   "source": [
    "### Check the kmean model with normalized dataset:\n",
    "model_normed = KMeans(n_clusters=20)\n",
    "model_normed.fit(X_normed.toarray())\n",
    "\n",
    "cluster_assigment_normed = model_normed.predict(X_normed.toarray())\n",
    "\n",
    "# Evaluate the model using various metrics\n",
    "silhouette = silhouette_score(X_normed, cluster_assigment_normed)\n",
    "print(silhouette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78b1200d-95b9-4b38-9a4b-2568af123361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09690581100858855\n"
     ]
    }
   ],
   "source": [
    "### Check the kmean model with tf-idf dataset:\n",
    "model_tfdf = KMeans(n_clusters=20)\n",
    "model_tfdf.fit(X_tfdf.toarray())\n",
    "\n",
    "cluster_assigment_tfdf = model_tfdf.predict(X_tfdf.toarray())\n",
    "\n",
    "# Evaluate the model using various metrics\n",
    "silhouette = silhouette_score(X_tfdf, cluster_assigment_tfdf)\n",
    "print(silhouette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bf18fd-ded3-4216-894b-a8e5577b8925",
   "metadata": {},
   "source": [
    "**Based on the silhouette score, we will choose the tfdf transformer as a method for text normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6920456-3793-4277-8eaf-85d7309fd0be",
   "metadata": {},
   "source": [
    "#### Perform hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a54b9a2-3817-474f-8bdf-b7a40a3f6707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best parameters: {'init': 'k-means++', 'n_clusters': 100}\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters to tune and their possible values\n",
    "param_grid = {\n",
    "    \"n_clusters\": [40,60,80,100],\n",
    "    \"init\": [\"k-means++\"],\n",
    "    #\"max_iter\": [300, 500, 1000],\n",
    "    #\"tol\": [1e-4, 1e-3, 1e-2]\n",
    "}\n",
    "\n",
    "# Define a scorer based on silhouette score for GridSearchCV\n",
    "def scorer(estimator, X, y=None):\n",
    "    y_pred = estimator.fit_predict(X)\n",
    "    return silhouette_score(X, y_pred)\n",
    "\n",
    "# Create a KMeans model\n",
    "kmeans = KMeans()\n",
    "\n",
    "# Create a GridSearchCV object to perform hyperparameter tuning\n",
    "kmeans_tuning = GridSearchCV(kmeans, param_grid, cv=5,\n",
    "                           scoring=scorer,\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "kmeans_tuning.fit(X_tfdf)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = kmeans_tuning.best_params_\n",
    "\n",
    "# Print the best parameters\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e08c32be-1a79-455b-8564-abb24221e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(samples, vectorizer, transformer, eval_model):\n",
    "      \n",
    "    new_samples = [\" \".join(word) for word in samples]\n",
    "    \n",
    "    # Transform the new category into numerical features\n",
    "    new_samples = transformer.transform(vectorizer.transform(new_samples))\n",
    "\n",
    "    # Get the prediction for the new category\n",
    "    prediction = eval_model.best_estimator_.predict(new_samples)\n",
    "    return prediction\n",
    "\n",
    "#Preprocess raw data\n",
    "categories = cat_df['categories'].apply(lambda x: split_and_replace(x))\n",
    "\n",
    "#Get predictions\n",
    "cat_df['predict_cat'] = get_category(categories, vectorizer, \n",
    "                                     transformer, kmeans_tuning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "52c42f30-d792-48f5-b49d-4dcd575f76cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END ....init=k-means++, n_clusters=100;, score=0.166 total time= 1.4min\n",
      "[CV 2/5] END ....init=k-means++, n_clusters=100;, score=0.159 total time= 1.6min\n",
      "[CV 3/5] END ....init=k-means++, n_clusters=100;, score=0.159 total time= 1.5min\n",
      "[CV 4/5] END ....init=k-means++, n_clusters=100;, score=0.127 total time= 1.7min\n",
      "[CV 5/5] END ....init=k-means++, n_clusters=100;, score=0.111 total time= 1.5min\n",
      "Best parameters: {'init': 'k-means++', 'n_clusters': 100}\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters to tune and their possible values\n",
    "param_grid = {\n",
    "    \"n_clusters\": [100],\n",
    "    \"init\": [\"k-means++\"],\n",
    "    #\"max_iter\": [300, 500, 1000],\n",
    "    #\"tol\": [1e-4, 1e-3, 1e-2]\n",
    "}\n",
    "\n",
    "# Define a scorer based on silhouette score for GridSearchCV\n",
    "def scorer(estimator, X, y=None):\n",
    "    y_pred = estimator.fit_predict(X)\n",
    "    return silhouette_score(X, y_pred)\n",
    "\n",
    "# Create a KMeans model\n",
    "kmeans = KMeans()\n",
    "\n",
    "# Create a GridSearchCV object to perform hyperparameter tuning\n",
    "kmeans_tuning = GridSearchCV(kmeans, param_grid, cv=5,\n",
    "                           scoring=scorer,\n",
    "                           verbose=3)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "kmeans_tuning.fit(X_vect)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = kmeans_tuning.best_params_\n",
    "\n",
    "# Print the best parameters\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f8da1df-c7fa-4801-ba2f-9e5b64b2e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess raw data\n",
    "categories = cat_df['categories'].apply(lambda x: split_and_replace(x))\n",
    "categories = [\" \".join(category) for category in categories]\n",
    "\n",
    "X_vect = vectorizer.transform(categories)\n",
    "\n",
    "#Get predictions\n",
    "cat_df['predict_cat'] = kmeans_tuning.best_estimator_.predict(X_vect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e113b36c-06e8-4cf5-bcc1-ef964494254e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63    2680\n",
       "94    1954\n",
       "32    1856\n",
       "98    1752\n",
       "7     1739\n",
       "      ... \n",
       "53     266\n",
       "8      241\n",
       "97     235\n",
       "51     166\n",
       "11     135\n",
       "Name: predict_cat, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df['predict_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c1f0e6d-8d41-4746-b010-e80f00bacbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8                   Food, Coffee & Tea\n",
      "11                  Coffee & Tea, Food\n",
      "138         Food, Donuts, Coffee & Tea\n",
      "149         Donuts, Coffee & Tea, Food\n",
      "177         Donuts, Food, Coffee & Tea\n",
      "179         Food, Coffee & Tea, Donuts\n",
      "186         Coffee & Tea, Food, Donuts\n",
      "187         Coffee & Tea, Donuts, Food\n",
      "284    Restaurants, Coffee & Tea, Food\n",
      "358    Food, Coffee & Tea, Restaurants\n"
     ]
    }
   ],
   "source": [
    "print(cat_df[cat_df['predict_cat']==7]['categories'][0:10].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d76b14b-8f3b-4c5a-8211-400b0595e10d",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32f7906e-5674-4b1c-99b1-830d3f79b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'kmeans_model.sav'\n",
    "pickle.dump(kmeans_tuning, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
